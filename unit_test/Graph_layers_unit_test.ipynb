{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graph_layers_unit_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "60YUkjcifKYl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a7fbff-c31f-4e27-f061-685a94af484b"
      },
      "source": [
        "!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "!pip install torch-geometric"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-scatter==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (11.9MB)\n",
            "\u001b[K     |████████████████████████████████| 11.9MB 54.3MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.5\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-sparse==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (24.3MB)\n",
            "\u001b[K     |████████████████████████████████| 24.3MB 139kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse==latest+cu101) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse==latest+cu101) (1.18.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.8\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-cluster==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_cluster-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (21.5MB)\n",
            "\u001b[K     |████████████████████████████████| 21.5MB 1.4MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.5.8\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-spline-conv==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_spline_conv-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 33.2MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.0\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/67/6c0bce6b6e6bc806e25d996e46a686e5a11254d89257983265a988bb02ee/torch_geometric-1.6.1.tar.gz (178kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 12.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.48.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.1.4)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 13.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Collecting ase\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/78/edadb45c7f26f8fbb99da81feadb561c26bb0393b6c5d1ac200ecdc12d61/ase-3.20.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 29.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.11.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (3.7.4.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (50.3.2)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ase->torch-geometric) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (1.3.1)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.6.1-cp36-none-any.whl size=308552 sha256=acb64a87a3b3579ba4a763907a8fa73fd94d5a6da3095f6f992e2cb2f038b274\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/25/ea/3d71d2088dccc63214fa59259dcc598ded4150a5f8b41d84ff\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, rdflib, ase, torch-geometric\n",
            "Successfully installed ase-3.20.1 isodate-0.6.0 rdflib-5.0.0 torch-geometric-1.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uWwRpYchR0l"
      },
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import RGCNConv,GlobalAttention\n",
        "from torch.nn.functional import one_hot\n",
        "from torch_geometric.datasets import QM9\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch_geometric.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from torch.nn import CosineSimilarity\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NmFB_3W9K7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fbeb6d8-4f89-4eea-b7b1-736cf34adfa5"
      },
      "source": [
        "data_QM9 = QM9('/content/data')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://pytorch-geometric.com/datasets/qm9_v2.zip\n",
            "Extracting /content/data/raw/qm9_v2.zip\n",
            "Processing...\n",
            "Using a pre-processed version of the dataset. Please install `rdkit` to alternatively process the raw data.\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMOIs5DWCShs"
      },
      "source": [
        "data = dataset[0] get one sample https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-OQfxZ2_yhp"
      },
      "source": [
        "g = data_QM9[100000]\n",
        "data = DataLoader(data_QM9,10,True)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvgWwvM5JKv9"
      },
      "source": [
        "for g in data_QM9:\n",
        "  if g.edge_attr.size()[1] != 4:\n",
        "    print('bug')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJR3urIQMRs5"
      },
      "source": [
        "for g in data_QM9:\n",
        "  if g.x.size()[1] != 11:\n",
        "    print('bug')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWosG3sKhgVY"
      },
      "source": [
        "def A_mat(data):   ### torch geometric graph to adjecency tensor\n",
        "\n",
        "  edge_type  = data.edge_attr\n",
        "  n_nodes    = data.num_nodes\n",
        "  adj_mat    = torch.zeros((n_nodes,n_nodes,edge_type.size()[1]))\n",
        "  edge_index = data.edge_index\n",
        "  \n",
        "  for i in range(data.num_edges):\n",
        "    k, m = edge_index[0,i],edge_index[1,i]\n",
        "    adj_mat[k,m,:] = edge_type[i,:]\n",
        "\n",
        "  return adj_mat.to(dtype = torch.float32)\n",
        "\n",
        "'''\n",
        "    R_i∈{0,…,|R|−1}\n",
        "'''\n",
        "\n",
        "def edge_type(data):\n",
        "  return torch.matmul(data.edge_attr, torch.tensor([0.,1.,2.,3.]).T).to(torch.long)\n",
        "\n",
        "\n",
        "def batch_convolve(batch,Conv_CUSTM):  #### \n",
        "  return torch.cat([Conv_CUSTM(A_mat(m).unsqueeze(0), m.x.unsqueeze(0)) for m in batch.to_data_list()],dim=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n15f9ICDbDSm"
      },
      "source": [
        "### The following convolution tested "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYO1Ot-FNW2K"
      },
      "source": [
        "class Convolve(torch.nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,n_relations):\n",
        "      super(Convolve,self).__init__()\n",
        "\n",
        "      '''\n",
        "       unclear type of weight initialization \n",
        "      '''\n",
        "\n",
        "      self.weight     = Parameter(torch.nn.init.xavier_uniform_(torch.empty(in_channels,out_channels,n_relations), gain=1.0))\n",
        "      self.lin        = nn.Linear(in_channels,out_channels)\n",
        "      \n",
        "    def forward(self,A,x):\n",
        "\n",
        "      #A       = A[:,:,:,:-1]\n",
        "      sum_     = torch.sum(A,dim=2)\n",
        "      norm     = 1./(sum_ + torch.full(sum_.size(),1e-15))  ## look for analytical solution\n",
        "      A_new    = torch.einsum('sijcd,sicd->sijcd',A.unsqueeze(4),norm.unsqueeze(3))\n",
        "      Theta_ij = torch.einsum('abc,sijcd->sijabd',self.weight,A_new).squeeze(-1)\n",
        "      x_new    = torch.einsum('sja,sijab->sib',x,Theta_ij) + self.lin(x)\n",
        "\n",
        "      return x_new"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPwDB6KbOink"
      },
      "source": [
        "### Convolve check "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g11OCGDTRk4Y"
      },
      "source": [
        "### Initialise custom and libriary convolution \n",
        "### operators with the same weights \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cKIPn7pQXFA"
      },
      "source": [
        "Conv_RGCN  = RGCNConv(11,3,4,root_weight=True)\n",
        "Conv_CUSTM = Convolve(11,3,4)\n",
        "\n",
        "params = []\n",
        "for param in Conv_RGCN.parameters():\n",
        "  params.append(param.data)\n",
        "\n",
        "theta, theta_root,_ = params\n",
        "\n",
        "Conv_CUSTM.weight.data = theta.permute(1,2,0)\n",
        "Conv_CUSTM.lin.weight.data = theta_root.T\n",
        "\n",
        "#Conv_CUSTM.lin.bias.data    = torch.tensor([1.,2.,0.3])\n",
        "#Conv_RGCN.bias.data    = torch.tensor([1.,2.,0.3])\n",
        "\n",
        "Conv_CUSTM.lin.bias.data  = Conv_RGCN.bias.data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTW-jBRd3Wus"
      },
      "source": [
        "### Compute node features for all graphs in QM9 dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFpyiVXTTexp"
      },
      "source": [
        "### Convolve check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0QJ5U9iUH3a"
      },
      "source": [
        "cos = nn.CosineSimilarity(dim=0)\n",
        "v1_ = []\n",
        "v2_ = []\n",
        "simillarity = []\n",
        "for batch in data:\n",
        "  v1  = batch_convolve(batch,Conv_CUSTM)[0].flatten()\n",
        "  v2  = Conv_RGCN(batch.x,batch.edge_index,edge_type(batch)).flatten()\n",
        "  sim = cos(v1,v2).detach().numpy()\n",
        "  if sim !=1:\n",
        "    simillarity.append(sim)\n",
        "    v1_.append(v1)\n",
        "    v2_.append(v2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtcTkLsaZo5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5477efe-777e-46ed-9827-3c65537b1c66"
      },
      "source": [
        "print('proportion of batches which do not have simmilarity equal to one = {}'.format(len(simillarity)/len(data)))\n",
        "print('divergence upper bound ={},divergence minimum bound ={}'.format(max(simillarity),min(simillarity)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "proportion of batches which do not have simmilarity equal to one = 0.11173952919596454\n",
            "divergence upper bound =1.000000238418579,divergence minimum bound =0.9999998211860657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqwT9VF26jeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35567cc-1327-4984-80a0-341d4af5a139"
      },
      "source": [
        "v1_[simillarity.index(max(simillarity))][:5], v2_[simillarity.index(max(simillarity))][:5]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.7653,  2.5251,  1.1903, -6.3267,  5.5478], grad_fn=<SliceBackward>),\n",
              " tensor([ 0.7653,  2.5251,  1.1903, -6.3267,  5.5478], grad_fn=<SliceBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLlHKzYl60d-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bac1ff8-e9d8-45ac-9f7f-4bf46481ffe3"
      },
      "source": [
        "v1_[simillarity.index(min(simillarity))][:5],v2_[simillarity.index(min(simillarity))][:5]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1.5972,  1.5825,  1.8130, -5.0916,  6.6822], grad_fn=<SliceBackward>),\n",
              " tensor([ 1.5972,  1.5825,  1.8130, -5.0916,  6.6822], grad_fn=<SliceBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtuFRuVXPS9U"
      },
      "source": [
        "### Convolve-Aggregate-Check "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsD3AAzRPYhs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "faad05f8-a4c8-486d-ee1e-f091bd6c78ec"
      },
      "source": [
        "hgate   = nn.Linear(3,1)\n",
        "h_theta = nn.Linear(3,2)\n",
        "lin_last = nn.Linear(2,1)\n",
        "'''\n",
        "  batch is a column vector which maps each node to its respective graph ###in the batch:\n",
        "  batch=[0⋯01⋯n−2n−1⋯n−1]⊤\n",
        "'''"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n  batch is a column vector which maps each node to its respective graph ###in the batch:\\n  batch=[0⋯01⋯n−2n−1⋯n−1]⊤\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGrENy6TQ2pV"
      },
      "source": [
        "class Net1(nn.Module):\n",
        "  def __init__(self,conv,gate_nn,nn,lin_last):\n",
        "    super(Net1, self).__init__()\n",
        "    self.agg  = GlobalAttention(gate_nn, nn)\n",
        "    self.conv = conv\n",
        "    self.lin  = lin_last\n",
        "  def forward(self,x):\n",
        "    x_new = self.conv(x.x,x.edge_index,edge_type(x))\n",
        "    output = self.agg(x_new,x.batch)\n",
        "    return self.lin(output)\n",
        "\n",
        "class Net2(Net1):\n",
        "  def forward(self,x):\n",
        "    x_new = torch.cat([self.conv(A_mat(m).unsqueeze(0), m.x.unsqueeze(0)) for m in x.to_data_list()],dim=1)\n",
        "    output = self.agg(x_new.squeeze(0),x.batch)\n",
        "    return self.lin(output)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1qvILa5oOLW"
      },
      "source": [
        "N1 = Net1(Conv_RGCN,hgate,h_theta,lin_last)\n",
        "N2 = Net2(Conv_CUSTM,hgate,h_theta,lin_last)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ouppsn9ntLNJ"
      },
      "source": [
        "v1_ = []\n",
        "v2_ = []\n",
        "simillarity = []\n",
        "for batch in data:\n",
        "  v1  = N1(batch).flatten()\n",
        "  v2  = N2(batch).flatten()\n",
        "  sim = cos(v1,v2).detach().numpy()\n",
        "  if sim !=1:\n",
        "    simillarity.append(sim)\n",
        "    v1_.append(v1)\n",
        "    v2_.append(v2)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry1lrU_HvV9Z",
        "outputId": "3fa35dce-5723-4cef-c640-d40454da91f4"
      },
      "source": [
        "print('proportion of batches which do not have simmilarity equal to one = {}'.format(len(simillarity)/len(data)))\n",
        "print('divergence upper bound ={},divergence minimum bound ={}'.format(max(simillarity),min(simillarity)))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "proportion of batches which do not have simmilarity equal to one = 0.22623051054723325\n",
            "divergence upper bound =1.0000001192092896,divergence minimum bound =0.9999997615814209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ffQysPH_TOd"
      },
      "source": [
        "### Generator Check "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZUbdQcA0Cr8"
      },
      "source": [
        "def permute3D(A):\n",
        "\n",
        "  A = A.permute(2,0,1)\n",
        "  A_new = torch.triu(A,diagonal=1) + torch.transpose(torch.triu(A,diagonal=1),1,2)\n",
        "\n",
        "  return A_new.permute(1,2,0)\n",
        "\n",
        "def permute4D(A):\n",
        "\n",
        "  bz,n,m,k = A.size()\n",
        "\n",
        "  A_new = A.permute(1,2,3,0)\n",
        "  A_new = A_new.reshape(n,m,-1)\n",
        "  A_new = permute3D(A_new)\n",
        "  A_new = A_new.reshape(n,m,k,bz)\n",
        "  A_new = A_new.permute(3,0,1,2)\n",
        "\n",
        "  return A_new\n",
        "\n",
        "\n",
        "class Generator(torch.nn.Module):\n",
        "\n",
        "    # N - maximum number of atoms\n",
        "    # T - number of atom types\n",
        "    # Y - number of bond types\n",
        "\n",
        "    #### Candidates to enforce A_sym = LL^T\n",
        "\n",
        "    def __init__(self,z_dim,N,T,Y,temp):\n",
        "      super(Generator, self).__init__()\n",
        "\n",
        "      self.N = N\n",
        "      self.T = T\n",
        "      self.Y = Y\n",
        "\n",
        "      self.temp = temp ### GambelSoftmax activation - temperature\n",
        "\n",
        "      self.lin1 = nn.Linear(z_dim,128)\n",
        "      self.lin2 = nn.Linear(128,256)\n",
        "      self.lin3 = nn.Linear(256,512)\n",
        "\n",
        "      self.edges = nn.Linear(512,self.N*self.N*self.Y)\n",
        "      self.nodes = nn.Linear(512,self.N*self.T)\n",
        "\n",
        "      self.act   = nn.functional.gumbel_softmax\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        output      = self.lin3(self.lin2(self.lin1(x)))\n",
        "\n",
        "        nodes_logit = self.nodes(output).view(-1,self.N,self.T)\n",
        "        nodes       = self.act(nodes_logit,dim=-1,tau=self.temp,hard=True)\n",
        "\n",
        "        edges_logit      = self.edges(output).view(-1,self.N,self.N,self.Y)\n",
        "        edges_logit_T    = torch.transpose(edges_logit,1,2)\n",
        "        edges_logit      = 0.5*(edges_logit+edges_logit_T)\n",
        "\n",
        "        edges_logit      = self.act(edges_logit,dim=-1,tau=self.temp,hard=True)\n",
        "\n",
        "        edges = permute4D(edges_logit)\n",
        "\n",
        "        return  nodes, edges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEO-ZMm4f1nt"
      },
      "source": [
        "G = Generator(10,9,5,4,0.1)\n",
        "\n",
        "def tensor_symmetry_check(A):\n",
        "  return torch.sum(A-torch.transpose(A,0,1)).detach().numpy()\n",
        "\n",
        "for _ in range(1000):\n",
        "  z = torch.rand((60,10))\n",
        "  X,A = G(z)\n",
        "  for a in A:\n",
        "    if tensor_symmetry_check(a) !=0 or torch.sum(torch.diagonal(a,dim1=0,dim2=1)).detach().numpy() !=0:\n",
        "      print('not symmetrical tensor or diagonal does not equal to [0,0,0,0]') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoJTKjX8i0rz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0fec4c-6f97-49c1-ee52-5171593ea19c"
      },
      "source": [
        "torch.diagonal(a,dim1=0,dim2=1).reshape(9,4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]], grad_fn=<UnsafeViewBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    }
  ]
}