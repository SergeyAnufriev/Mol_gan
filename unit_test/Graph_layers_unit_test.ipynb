{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60YUkjcifKYl",
    "outputId": "d6a7fbff-c31f-4e27-f061-685a94af484b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
      "Collecting torch-scatter==latest+cu101\n",
      "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (11.9MB)\n",
      "\u001b[K     |████████████████████████████████| 11.9MB 54.3MB/s \n",
      "\u001b[?25hInstalling collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.0.5\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
      "Collecting torch-sparse==latest+cu101\n",
      "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (24.3MB)\n",
      "\u001b[K     |████████████████████████████████| 24.3MB 139kB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse==latest+cu101) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse==latest+cu101) (1.18.5)\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.8\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
      "Collecting torch-cluster==latest+cu101\n",
      "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_cluster-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (21.5MB)\n",
      "\u001b[K     |████████████████████████████████| 21.5MB 1.4MB/s \n",
      "\u001b[?25hInstalling collected packages: torch-cluster\n",
      "Successfully installed torch-cluster-1.5.8\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
      "Collecting torch-spline-conv==latest+cu101\n",
      "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_spline_conv-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.4MB)\n",
      "\u001b[K     |████████████████████████████████| 6.4MB 33.2MB/s \n",
      "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
      "Successfully installed torch-spline-conv-1.2.0\n",
      "Collecting torch-geometric\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/67/6c0bce6b6e6bc806e25d996e46a686e5a11254d89257983265a988bb02ee/torch_geometric-1.6.1.tar.gz (178kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 12.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.7.0+cu101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.18.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (4.41.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.48.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.23.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.1.4)\n",
      "Collecting rdflib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 13.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
      "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
      "Collecting ase\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/78/edadb45c7f26f8fbb99da81feadb561c26bb0393b6c5d1ac200ecdc12d61/ase-3.20.1-py3-none-any.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2MB 29.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.11.2)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.16.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.7)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (3.7.4.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.17.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (50.3.2)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
      "Collecting isodate\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ase->torch-geometric) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->torch-geometric) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (1.3.1)\n",
      "Building wheels for collected packages: torch-geometric\n",
      "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torch-geometric: filename=torch_geometric-1.6.1-cp36-none-any.whl size=308552 sha256=acb64a87a3b3579ba4a763907a8fa73fd94d5a6da3095f6f992e2cb2f038b274\n",
      "  Stored in directory: /root/.cache/pip/wheels/e6/25/ea/3d71d2088dccc63214fa59259dcc598ded4150a5f8b41d84ff\n",
      "Successfully built torch-geometric\n",
      "Installing collected packages: isodate, rdflib, ase, torch-geometric\n",
      "Successfully installed ase-3.20.1 isodate-0.6.0 rdflib-5.0.0 torch-geometric-1.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
    "!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
    "!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
    "!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5uWwRpYchR0l"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import RGCNConv,GlobalAttention\n",
    "from torch.nn.functional import one_hot\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.nn import CosineSimilarity\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NmFB_3W9K7C",
    "outputId": "2fbeb6d8-4f89-4eea-b7b1-736cf34adfa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://pytorch-geometric.com/datasets/qm9_v2.zip\n",
      "Extracting /content/data/raw/qm9_v2.zip\n",
      "Processing...\n",
      "Using a pre-processed version of the dataset. Please install `rdkit` to alternatively process the raw data.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data_QM9 = QM9('/content/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMOIs5DWCShs"
   },
   "source": [
    "data = dataset[0] get one sample https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "7-OQfxZ2_yhp"
   },
   "outputs": [],
   "source": [
    "g = data_QM9[100000]\n",
    "data = DataLoader(data_QM9,10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fvgWwvM5JKv9"
   },
   "outputs": [],
   "source": [
    "for g in data_QM9:\n",
    "  if g.edge_attr.size()[1] != 4:\n",
    "    print('bug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RJR3urIQMRs5"
   },
   "outputs": [],
   "source": [
    "for g in data_QM9:\n",
    "  if g.x.size()[1] != 11:\n",
    "    print('bug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vWosG3sKhgVY"
   },
   "outputs": [],
   "source": [
    "def A_mat(data):   ### torch geometric graph to adjecency tensor\n",
    "\n",
    "  edge_type  = data.edge_attr\n",
    "  n_nodes    = data.num_nodes\n",
    "  adj_mat    = torch.zeros((n_nodes,n_nodes,edge_type.size()[1]))\n",
    "  edge_index = data.edge_index\n",
    "  \n",
    "  for i in range(data.num_edges):\n",
    "    k, m = edge_index[0,i],edge_index[1,i]\n",
    "    adj_mat[k,m,:] = edge_type[i,:]\n",
    "\n",
    "  return adj_mat.to(dtype = torch.float32)\n",
    "\n",
    "'''\n",
    "    R_i∈{0,…,|R|−1}\n",
    "'''\n",
    "\n",
    "def edge_type(data):\n",
    "  return torch.matmul(data.edge_attr, torch.tensor([0.,1.,2.,3.]).T).to(torch.long)\n",
    "\n",
    "\n",
    "def batch_convolve(batch,Conv_CUSTM):  #### \n",
    "  return torch.cat([Conv_CUSTM(A_mat(m).unsqueeze(0), m.x.unsqueeze(0)) for m in batch.to_data_list()],dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n15f9ICDbDSm"
   },
   "source": [
    "### The following convolution tested "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kYO1Ot-FNW2K"
   },
   "outputs": [],
   "source": [
    "class Convolve(torch.nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,n_relations):\n",
    "      super(Convolve,self).__init__()\n",
    "\n",
    "      '''\n",
    "       unclear type of weight initialization \n",
    "      '''\n",
    "\n",
    "      self.weight     = Parameter(torch.nn.init.xavier_uniform_(torch.empty(in_channels,out_channels,n_relations), gain=1.0))\n",
    "      self.lin        = nn.Linear(in_channels,out_channels)\n",
    "      \n",
    "    def forward(self,A,x):\n",
    "\n",
    "      #A       = A[:,:,:,:-1]\n",
    "      sum_     = torch.sum(A,dim=2)\n",
    "      norm     = 1./(sum_ + torch.full(sum_.size(),1e-15))  ## look for analytical solution\n",
    "      A_new    = torch.einsum('sijcd,sicd->sijcd',A.unsqueeze(4),norm.unsqueeze(3))\n",
    "      Theta_ij = torch.einsum('abc,sijcd->sijabd',self.weight,A_new).squeeze(-1)\n",
    "      x_new    = torch.einsum('sja,sijab->sib',x,Theta_ij) + self.lin(x)\n",
    "\n",
    "      return x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPwDB6KbOink"
   },
   "source": [
    "### Convolve check "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g11OCGDTRk4Y"
   },
   "source": [
    "### Initialise custom and libriary convolution \n",
    "### operators with the same weights \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_cKIPn7pQXFA"
   },
   "outputs": [],
   "source": [
    "Conv_RGCN  = RGCNConv(11,3,4,root_weight=True)\n",
    "Conv_CUSTM = Convolve(11,3,4)\n",
    "\n",
    "params = []\n",
    "for param in Conv_RGCN.parameters():\n",
    "  params.append(param.data)\n",
    "\n",
    "theta, theta_root,_ = params\n",
    "\n",
    "Conv_CUSTM.weight.data = theta.permute(1,2,0)\n",
    "Conv_CUSTM.lin.weight.data = theta_root.T\n",
    "\n",
    "#Conv_CUSTM.lin.bias.data    = torch.tensor([1.,2.,0.3])\n",
    "#Conv_RGCN.bias.data    = torch.tensor([1.,2.,0.3])\n",
    "\n",
    "Conv_CUSTM.lin.bias.data  = Conv_RGCN.bias.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTW-jBRd3Wus"
   },
   "source": [
    "### Compute node features for all graphs in QM9 dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFpyiVXTTexp"
   },
   "source": [
    "### Convolve check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Q0QJ5U9iUH3a"
   },
   "outputs": [],
   "source": [
    "cos = nn.CosineSimilarity(dim=0)\n",
    "v1_ = []\n",
    "v2_ = []\n",
    "simillarity = []\n",
    "for batch in data:\n",
    "  v1  = batch_convolve(batch,Conv_CUSTM)[0].flatten()\n",
    "  v2  = Conv_RGCN(batch.x,batch.edge_index,edge_type(batch)).flatten()\n",
    "  sim = cos(v1,v2).detach().numpy()\n",
    "  if sim !=1:\n",
    "    simillarity.append(sim)\n",
    "    v1_.append(v1)\n",
    "    v2_.append(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtcTkLsaZo5m",
    "outputId": "f5477efe-777e-46ed-9827-3c65537b1c66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion of batches which do not have simmilarity equal to one = 0.11173952919596454\n",
      "divergence upper bound =1.000000238418579,divergence minimum bound =0.9999998211860657\n"
     ]
    }
   ],
   "source": [
    "print('proportion of batches which do not have simmilarity equal to one = {}'.format(len(simillarity)/len(data)))\n",
    "print('divergence upper bound ={},divergence minimum bound ={}'.format(max(simillarity),min(simillarity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqwT9VF26jeo",
    "outputId": "d35567cc-1327-4984-80a0-341d4af5a139"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.7653,  2.5251,  1.1903, -6.3267,  5.5478], grad_fn=<SliceBackward>),\n",
       " tensor([ 0.7653,  2.5251,  1.1903, -6.3267,  5.5478], grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1_[simillarity.index(max(simillarity))][:5], v2_[simillarity.index(max(simillarity))][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLlHKzYl60d-",
    "outputId": "7bac1ff8-e9d8-45ac-9f7f-4bf46481ffe3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.5972,  1.5825,  1.8130, -5.0916,  6.6822], grad_fn=<SliceBackward>),\n",
       " tensor([ 1.5972,  1.5825,  1.8130, -5.0916,  6.6822], grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1_[simillarity.index(min(simillarity))][:5],v2_[simillarity.index(min(simillarity))][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtuFRuVXPS9U"
   },
   "source": [
    "### Convolve-Aggregate-Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "fsD3AAzRPYhs",
    "outputId": "faad05f8-a4c8-486d-ee1e-f091bd6c78ec"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n  batch is a column vector which maps each node to its respective graph ###in the batch:\\n  batch=[0⋯01⋯n−2n−1⋯n−1]⊤\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgate   = nn.Linear(3,1)\n",
    "h_theta = nn.Linear(3,2)\n",
    "lin_last = nn.Linear(2,1)\n",
    "'''\n",
    "  batch is a column vector which maps each node to its respective graph ###in the batch:\n",
    "  batch=[0⋯01⋯n−2n−1⋯n−1]⊤\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "lGrENy6TQ2pV"
   },
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "  def __init__(self,conv,gate_nn,nn,lin_last):\n",
    "    super(Net1, self).__init__()\n",
    "    self.agg  = GlobalAttention(gate_nn, nn)\n",
    "    self.conv = conv\n",
    "    self.lin  = lin_last\n",
    "  def forward(self,x):\n",
    "    x_new = self.conv(x.x,x.edge_index,edge_type(x))\n",
    "    output = self.agg(x_new,x.batch)\n",
    "    return self.lin(output)\n",
    "\n",
    "class Net2(Net1):\n",
    "  def forward(self,x):\n",
    "    x_new = torch.cat([self.conv(A_mat(m).unsqueeze(0), m.x.unsqueeze(0)) for m in x.to_data_list()],dim=1)\n",
    "    output = self.agg(x_new.squeeze(0),x.batch)\n",
    "    return self.lin(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "_1qvILa5oOLW"
   },
   "outputs": [],
   "source": [
    "N1 = Net1(Conv_RGCN,hgate,h_theta,lin_last)\n",
    "N2 = Net2(Conv_CUSTM,hgate,h_theta,lin_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "Ouppsn9ntLNJ"
   },
   "outputs": [],
   "source": [
    "v1_ = []\n",
    "v2_ = []\n",
    "simillarity = []\n",
    "for batch in data:\n",
    "  v1  = N1(batch).flatten()\n",
    "  v2  = N2(batch).flatten()\n",
    "  sim = cos(v1,v2).detach().numpy()\n",
    "  if sim !=1:\n",
    "    simillarity.append(sim)\n",
    "    v1_.append(v1)\n",
    "    v2_.append(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ry1lrU_HvV9Z",
    "outputId": "3fa35dce-5723-4cef-c640-d40454da91f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion of batches which do not have simmilarity equal to one = 0.22623051054723325\n",
      "divergence upper bound =1.0000001192092896,divergence minimum bound =0.9999997615814209\n"
     ]
    }
   ],
   "source": [
    "print('proportion of batches which do not have simmilarity equal to one = {}'.format(len(simillarity)/len(data)))\n",
    "print('divergence upper bound ={},divergence minimum bound ={}'.format(max(simillarity),min(simillarity)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ffQysPH_TOd"
   },
   "source": [
    "### Generator Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZUbdQcA0Cr8"
   },
   "outputs": [],
   "source": [
    "def permute3D(A):\n",
    "\n",
    "  A = A.permute(2,0,1)\n",
    "  A_new = torch.triu(A,diagonal=1) + torch.transpose(torch.triu(A,diagonal=1),1,2)\n",
    "\n",
    "  return A_new.permute(1,2,0)\n",
    "\n",
    "def permute4D(A):\n",
    "\n",
    "  bz,n,m,k = A.size()\n",
    "\n",
    "  A_new = A.permute(1,2,3,0)\n",
    "  A_new = A_new.reshape(n,m,-1)\n",
    "  A_new = permute3D(A_new)\n",
    "  A_new = A_new.reshape(n,m,k,bz)\n",
    "  A_new = A_new.permute(3,0,1,2)\n",
    "\n",
    "  return A_new\n",
    "\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "\n",
    "    # N - maximum number of atoms\n",
    "    # T - number of atom types\n",
    "    # Y - number of bond types\n",
    "\n",
    "    #### Candidates to enforce A_sym = LL^T\n",
    "\n",
    "    def __init__(self,z_dim,N,T,Y,temp):\n",
    "      super(Generator, self).__init__()\n",
    "\n",
    "      self.N = N\n",
    "      self.T = T\n",
    "      self.Y = Y\n",
    "\n",
    "      self.temp = temp ### GambelSoftmax activation - temperature\n",
    "\n",
    "      self.lin1 = nn.Linear(z_dim,128)\n",
    "      self.lin2 = nn.Linear(128,256)\n",
    "      self.lin3 = nn.Linear(256,512)\n",
    "\n",
    "      self.edges = nn.Linear(512,self.N*self.N*self.Y)\n",
    "      self.nodes = nn.Linear(512,self.N*self.T)\n",
    "\n",
    "      self.act   = nn.functional.gumbel_softmax\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        output      = self.lin3(self.lin2(self.lin1(x)))\n",
    "\n",
    "        nodes_logit = self.nodes(output).view(-1,self.N,self.T)\n",
    "        nodes       = self.act(nodes_logit,dim=-1,tau=self.temp,hard=True)\n",
    "\n",
    "        edges_logit      = self.edges(output).view(-1,self.N,self.N,self.Y)\n",
    "        edges_logit_T    = torch.transpose(edges_logit,1,2)\n",
    "        edges_logit      = 0.5*(edges_logit+edges_logit_T)\n",
    "\n",
    "        edges_logit      = self.act(edges_logit,dim=-1,tau=self.temp,hard=True)\n",
    "\n",
    "        edges = permute4D(edges_logit)\n",
    "\n",
    "        return  nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEO-ZMm4f1nt"
   },
   "outputs": [],
   "source": [
    "G = Generator(10,9,5,4,0.1)\n",
    "\n",
    "def tensor_symmetry_check(A):\n",
    "  return torch.sum(A-torch.transpose(A,0,1)).detach().numpy()\n",
    "\n",
    "for _ in range(1000):\n",
    "  z = torch.rand((60,10))\n",
    "  X,A = G(z)\n",
    "  for a in A:\n",
    "    if tensor_symmetry_check(a) !=0 or torch.sum(torch.diagonal(a,dim1=0,dim2=1)).detach().numpy() !=0:\n",
    "      print('not symmetrical tensor or diagonal does not equal to [0,0,0,0]') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QoJTKjX8i0rz",
    "outputId": "db0fec4c-6f97-49c1-ee52-5171593ea19c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 144,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diagonal(a,dim1=0,dim2=1).reshape(9,4)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Graph_layers_unit_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
